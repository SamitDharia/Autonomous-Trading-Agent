{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "![QuantConnect Logo](https://cdn.quantconnect.com/web/i/icon.png)\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "qb = QuantBook()\n",
    "sym = qb.AddEquity(\"TSLA\", Resolution.Minute).Symbol\n",
    "# extend history for more regimes\n",
    "hist = qb.History(sym, start=datetime(2018,1,1), end=datetime(2022,1,1), resolution=Resolution.Minute)\n",
    "\n",
    "# Resample to 5-minute\n",
    "df = hist.loc[sym].reset_index().rename(columns={\"time\":\"timestamp\"})\n",
    "df = df.set_index(\"timestamp\").sort_index()\n",
    "df5 = pd.DataFrame({\n",
    "    \"open\": df[\"open\"].resample(\"5min\").first(),\n",
    "    \"high\": df[\"high\"].resample(\"5min\").max(),\n",
    "    \"low\": df[\"low\"].resample(\"5min\").min(),\n",
    "    \"close\": df[\"close\"].resample(\"5min\").last(),\n",
    "    \"volume\": df[\"volume\"].resample(\"5min\").sum(),\n",
    "}).dropna()\n",
    "\n",
    "def rsi(series, period=14):\n",
    "    delta = series.diff()\n",
    "    up = delta.clip(lower=0)\n",
    "    down = -delta.clip(upper=0)\n",
    "    roll_up = up.ewm(alpha=1/period, adjust=False).mean()\n",
    "    roll_down = down.ewm(alpha=1/period, adjust=False).mean() + 1e-9\n",
    "    rs = roll_up / roll_down\n",
    "    return 100 - (100 / (1 + rs))\n",
    "\n",
    "def macd(series, fast=12, slow=26, signal=9):\n",
    "    ema_fast = series.ewm(span=fast, adjust=False).mean()\n",
    "    ema_slow = series.ewm(span=slow, adjust=False).mean()\n",
    "    line = ema_fast - ema_slow\n",
    "    sig = line.ewm(span=signal, adjust=False).mean()\n",
    "    hist = line - sig\n",
    "    return line, sig, hist\n",
    "\n",
    "def atr(df, period=14):\n",
    "    hl = df[\"high\"] - df[\"low\"]\n",
    "    hc = (df[\"high\"] - df[\"close\"].shift()).abs()\n",
    "    lc = (df[\"low\"] - df[\"close\"].shift()).abs()\n",
    "    tr = pd.concat([hl, hc, lc], axis=1).max(axis=1)\n",
    "    return tr.ewm(alpha=1/period, adjust=False).mean()\n",
    "\n",
    "close = df5[\"close\"]\n",
    "ret1 = close.pct_change()\n",
    "ema20 = close.ewm(span=20, adjust=False).mean()\n",
    "ema50 = close.ewm(span=50, adjust=False).mean()\n",
    "ema200 = close.ewm(span=200, adjust=False).mean()\n",
    "rsi14 = rsi(close)\n",
    "rsi_slope = rsi14.diff()\n",
    "macd_line, macd_sig, macd_hist = macd(close)\n",
    "macd_slope = macd_line.diff()\n",
    "atr14 = atr(df5)\n",
    "atr_pct = atr14 / close\n",
    "bb_mid = close.rolling(20).mean()\n",
    "bb_std = close.rolling(20).std()\n",
    "bb_z = (close - bb_mid) / (2 * bb_std + 1e-9)\n",
    "vol20 = ret1.rolling(20).std()\n",
    "vol_z = (vol20 - vol20.rolling(100).mean()) / (vol20.rolling(100).std() + 1e-9)\n",
    "vol_z = vol_z.fillna(0)\n",
    "volm_z = (df5[\"volume\"] - df5[\"volume\"].rolling(20).mean()) / (df5[\"volume\"].rolling(20).std() + 1e-9)\n",
    "volm_z = volm_z.fillna(0)\n",
    "tod = df5.index.hour + df5.index.minute/60.0\n",
    "tod_sin = np.sin(2*np.pi*tod/24)\n",
    "tod_cos = np.cos(2*np.pi*tod/24)\n",
    "\n",
    "df_feat = pd.DataFrame({\n",
    "    \"rsi\": rsi14,\n",
    "    \"rsi_slope\": rsi_slope,\n",
    "    \"macd\": macd_line,\n",
    "    \"macd_sig\": macd_sig,\n",
    "    \"macd_hist\": macd_hist,\n",
    "    \"macd_slope\": macd_slope,\n",
    "    \"ema20\": ema20,\n",
    "    \"ema50\": ema50,\n",
    "    \"ema200\": ema200,\n",
    "    \"ema20_rel\": close/ema20 - 1,\n",
    "    \"ema50_rel\": close/ema50 - 1,\n",
    "    \"ema200_rel\": close/ema200 - 1,\n",
    "    \"atr\": atr14,\n",
    "    \"atr_pct\": atr_pct,\n",
    "    \"bb_z\": bb_z,\n",
    "    \"ret1\": ret1,\n",
    "    \"vol20\": vol20,\n",
    "    \"vol_z\": vol_z,\n",
    "    \"volm_z\": volm_z,\n",
    "    \"tod\": tod,\n",
    "    \"tod_sin\": tod_sin,\n",
    "    \"tod_cos\": tod_cos,\n",
    "})\n",
    "\n",
    "# Label: 60-minute forward net return > cost threshold\n",
    "fwd = close.shift(-12)\n",
    "ret_fwd = (fwd - close) / close\n",
    "cost_bps = 0.0005  # 5 bps to approximate costs/slippage\n",
    "df_feat[\"label\"] = (ret_fwd > cost_bps).astype(int)\n",
    "df_feat = df_feat.dropna()\n",
    "\n",
    "X = df_feat.drop(columns=[\"label\"])\n",
    "y = df_feat[\"label\"]\n",
    "\n",
    "# time-based split\n",
    "split_idx = int(len(X)*0.8)\n",
    "X_train, X_val = X.iloc[:split_idx], X.iloc[split_idx:]\n",
    "y_train, y_val = y.iloc[:split_idx], y.iloc[split_idx:]\n",
    "\n",
    "def best_logit(Xtr, ytr, Xvl, yvl, Cs=(0.1,0.5,1.0,2.0,5.0)):\n",
    "    best = None\n",
    "    best_auc = -1\n",
    "    for c in Cs:\n",
    "        lr = LogisticRegression(max_iter=500, random_state=42, C=c, penalty=\"l2\")\n",
    "        lr.fit(Xtr, ytr)\n",
    "        p = lr.predict_proba(Xvl)[:,1]\n",
    "        auc = roc_auc_score(yvl.iloc[:len(p)], p)\n",
    "        if auc > best_auc:\n",
    "            best_auc = auc\n",
    "            best = lr\n",
    "    return best, best_auc\n",
    "\n",
    "# Train experts on small feature subsets\n",
    "rsi_feats = [\"rsi\", \"rsi_slope\", \"bb_z\"]\n",
    "macd_feats = [\"macd\", \"macd_sig\", \"macd_hist\", \"macd_slope\"]\n",
    "trend_feats = [\"ema20_rel\", \"ema50_rel\", \"ema200_rel\"]\n",
    "\n",
    "rsi_clf, rsi_auc = best_logit(X_train[rsi_feats], y_train, X_val[rsi_feats], y_val)\n",
    "macd_clf, macd_auc = best_logit(X_train[macd_feats], y_train, X_val[macd_feats], y_val)\n",
    "trend_clf, trend_auc = best_logit(X_train[trend_feats], y_train, X_val[trend_feats], y_val)\n",
    "\n",
    "# Brain input: expert probs + regime\n",
    "rsi_p_tr = rsi_clf.predict_proba(X_train[rsi_feats])[:,1]\n",
    "macd_p_tr = macd_clf.predict_proba(X_train[macd_feats])[:,1]\n",
    "trend_p_tr = trend_clf.predict_proba(X_train[trend_feats])[:,1]\n",
    "regime_tr = X_train[[\"atr_pct\", \"tod_sin\", \"tod_cos\", \"vol_z\"]]\n",
    "brain_tr = pd.DataFrame({\n",
    "    \"rsi\": rsi_p_tr,\n",
    "    \"macd\": macd_p_tr,\n",
    "    \"trend\": trend_p_tr,\n",
    "    \"volatility\": regime_tr[\"atr_pct\"],\n",
    "    \"tod_sin\": regime_tr[\"tod_sin\"],\n",
    "    \"tod_cos\": regime_tr[\"tod_cos\"],\n",
    "    \"vol_z\": regime_tr[\"vol_z\"],\n",
    "})\n",
    "\n",
    "rsi_p_va = rsi_clf.predict_proba(X_val[rsi_feats])[:,1]\n",
    "macd_p_va = macd_clf.predict_proba(X_val[macd_feats])[:,1]\n",
    "trend_p_va = trend_clf.predict_proba(X_val[trend_feats])[:,1]\n",
    "regime_va = X_val[[\"atr_pct\", \"tod_sin\", \"tod_cos\", \"vol_z\"]]\n",
    "brain_va = pd.DataFrame({\n",
    "    \"rsi\": rsi_p_va,\n",
    "    \"macd\": macd_p_va,\n",
    "    \"trend\": trend_p_va,\n",
    "    \"volatility\": regime_va[\"atr_pct\"],\n",
    "    \"tod_sin\": regime_va[\"tod_sin\"],\n",
    "    \"tod_cos\": regime_va[\"tod_cos\"],\n",
    "    \"vol_z\": regime_va[\"vol_z\"],\n",
    "})\n",
    "\n",
    "brain_clf, brain_auc = best_logit(brain_tr, y_train.loc[brain_tr.index], brain_va, y_val.loc[brain_va.index])\n",
    "\n",
    "def to_json(clf, feature_names):\n",
    "    coef = clf.coef_[0]\n",
    "    bias = float(clf.intercept_[0])\n",
    "    weights = {name: float(w) for name, w in zip(feature_names, coef)}\n",
    "    return {\"type\": \"logistic\", \"bias\": bias, \"weights\": weights}\n",
    "\n",
    "rsi_json = to_json(rsi_clf, rsi_feats)\n",
    "macd_json = to_json(macd_clf, macd_feats)\n",
    "trend_json = to_json(trend_clf, trend_feats)\n",
    "brain_json = to_json(brain_clf, [\"experts.rsi\", \"experts.macd\", \"experts.trend\", \"regime.volatility\", \"regime.tod_sin\", \"regime.tod_cos\", \"regime.vol_z\"])\n",
    "\n",
    "out = Path(\"output\")\n",
    "out.mkdir(parents=True, exist_ok=True)\n",
    "(out / \"rsi_expert.json\").write_text(json.dumps(rsi_json, indent=2))\n",
    "(out / \"macd_expert.json\").write_text(json.dumps(macd_json, indent=2))\n",
    "(out / \"trend_expert.json\").write_text(json.dumps(trend_json, indent=2))\n",
    "(out / \"brain.json\").write_text(json.dumps(brain_json, indent=2))\n",
    "\n",
    "print(\"Saved models to output/*.json\")\n",
    "print(\"AUCs (val):\", {\"RSI\": rsi_auc, \"MACD\": macd_auc, \"Trend\": trend_auc, \"Brain_val_proxy\": brain_auc})\n",
    "\n",
    "# Print JSONs to copy/paste if you prefer not to download\n",
    "for fname, blob in [\n",
    "    (\"rsi_expert.json\", rsi_json),\n",
    "    (\"macd_expert.json\", macd_json),\n",
    "    (\"trend_expert.json\", trend_json),\n",
    "    (\"brain.json\", brain_json),\n",
    "]:\n",
    "    print(f\"\\n=== {fname} ===\\n{json.dumps(blob, indent=2)}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Foundation-Autogluon",
   "language": "python",
   "name": "foundation-autogluon"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
